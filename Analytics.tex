

\chapter{Analytics}
\label{Analytics}

Twitter hat sich bei Privatpersonen, als auch Unternehmen und Massenmedien als Kommunikationstool durchgesetzt.
Die gewaltige Datenbasis die Twitter bietet, birgt dabei großes Potenzial, Erkenntnisse und Informationen über die Nutzer zu gewinnen.
Vom Aufspüren von aktuellen Trends und Thematiken, über die Generierung von Stimmungsbildern zu bestimmten Inhalten, bis zu Verhaltensanalyse einzelner Nutzer sind viele Szenarien denkbar.
Im Folgenden wird ein Ansatz innerhalb des Hamaube-System vorgestellt, Analysen einerseits in Echtzeit durchzuführen und andererseits Unmengen von gesammelten Daten effizient zu verarbeiten.

Alle eingehenden Twitter-Nachrichten werden durch eine Streamverarbeitung behandelt, erste Analysen durchgeführt und für eine spätere Batch-Analyse vorbereitet.

Zunächst wird die Streamverarbeitung und anschließend die Batch-Analyse vorgestellt.

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=\textwidth]{pics/analytics/archi}
	\caption{Übersicht der Analytics Komponenten}
\end{figure}

\section{Stream}

Die Streamverarbeitung innerhalb des Hamaube-Systems ist als eigenständiger Service geschrieben. Für die Umsetzung wurde SparkStreaming im Verbund mit Scala verwendet.

Folgende Ziele haben sich während des Projekt herausgebildet:
\begin{itemize}
	\item Vorverarbeitung der eingehenden Tweets für eine spätere Prozessierung mittels Spark
	\item Verarbeitung der Streamdaten für live Analyseergebnisse.
\end{itemize}


Als Input dienen bisher die beiden gegebenen Datenquellen:
\begin{enumerate}
	\item Tweets, welche aus der Twitter API in unsere Anwendung gestreamt werden.
	\item Hamaube-Tweets, welche in unserer Anwendung erzeugt werden.
\end{enumerate}

Auch die Streamverarbeitung ist über Kafka angebunden und erhält die Tweets über das \textit{USER\_ISSUES\_TWEET} Topic.


\subsection*{Vorverarbeitung für Spark Batch Processing}
Aus verschiedenen Gründen wurde für die Tweets im Hamaube-System das Datenmodell von Twitter übernommen.
Dadurch enthalten Tweets (vorallem solche, die direkt von Twitter kommen) eine Vielzahl von nicht gesetzten Feldern oder Daten, welche für die Analyse wenig interessant sind.
In der Vorverarbeitung wird nur ein definierter Teil der Felder eines Tweets übernommen und der Rest verworfen.
Zusätzlich werden (sofern vorhanden) die im Tweet enthaltenen Hashtags extrahiert und neben dem eigentlichen Tweet gespeichert.
Außerdem wird anhand des Tweet-Textes eine Sentiment Analyse durchgeführt, welche dem Tweet einen Score zuordnet, der dessen Stimmung widerspiegelt (negativ - negative Stimmung, positiv - positive Stimmung). Auch dieser Score wird neben dem eigentlichen Tweet gespeichert.

Wir haben uns dazu entschieden, die Tweetdaten zusätzlich - also dupliziert - zu den schon gespeicherten Tweets des 'CassandraReaders' in Cassandra zu speichern, da wir in Hinsicht auf ein produktives System die kritischen Tabellen nicht zusätzlich mit Anfragen belasten wollen.
Für die Analyse würde also ein separate Umgebung für Cassandra aufgebaut, dies haben im Hamaube-System aufgrund der Einfachheit noch nicht umgesetzt.

\subsection*{Live Analyse}
Zudem wird auf den durch Kafka eingehenden Tweetstream eine Live Analyse durchgeführt.
Das Spark Streaming Framework teilt den Stream dafür in Micro-Batches, die dann weiter verarbeitet werden können.
So werden z.B. die Anzahl von Hashtag pro Stunde/pro Minute ermittelt, daraus werden dann aktuell beliebte Hashtags erkannt.
Auch diese Ergebnisse werden in Cassandra gespeichert.
Um eine Skalierung zu ermöglichen müssen die Ergebnisse z.B. pro Stunde von mehreren Instanzen geupdated werden können, ohne dass dabei dirty reads oder Überschreibungen auftreten dürfen. Cassandra bietet hier den Datentyp \textbf{Counter}, der atomare \textit{increase} und \textit{decrease} Operationen anbietet. Damit lassen sich die meisten Szenarien realisieren, ohne weitere  komplexe (und möglicherweise verlangsamende) Isolierungsmechaniken zu implementieren.
\begin{figure}[htbp!]
\centering
\includegraphics[width=\linewidth]{pics/analytics/streamProcessing.pdf}
\caption{Spark stream processing}
\label{fig:streamProcessing}
\end{figure}

\subsection*{Beispiel}

Der Spark Streaming Service erhält einen neuen Tweet aus dem Topic \textit{USER\_ISSUES\_TWEET}.
Dieser liegt im vom Twitter definierten Datenformat vor (Siehe \ref{chap:cassandra}).

Folgende Attribute werden für die Weitervearbeitung extrahiert:
\begin{itemize}
	\item Tweet-Id
	\item Tweet-Text
	\item User (Id, Name)
	\item Sensitivitäts-Flag 
	\item Hashtags
	\item Erstellungsdatum
	\item Sprache
	\item Ort (Land, Stadt)
	\item GPS-Koordinaten
\end{itemize}

Twitter extrahiert dabei die Hashtags aus dem Tweet-Text und schreibt diese zusätzlich in ein Entity-Objekt, welches am Tweet hängt.
Diese Hashtags können einfach genutzt werden und eine Extraktion aus dem Text wird vermieden.
Falls Werte nicht gesetzt sind oder ungültig sind, werden diese durch einheitliche Dummy-Werte ersetzt, welche in späteren Analysen erkannt und übersprungen werden.
Anschließend wird die Sentiment-Analyse des Tweet-Textes durchgeführt. Diese zählt anhand definierter Listen positive und negative Wörter im Text und berechnet daraus einen Score. Dieser Score kann später z.B. mit den zum Tweet gehörenden Hashtags analysiert werden, ein mögliches Szenario wäre ein Stimmungsbild zu einem bestimmten Hashtag.
Damit eingehende Tweets in Zeiteinheiten aggregiert werden können,
wird der Erstellungszeitpunkt eines Tweets auf entsprechende Zeiteinheiten abgerundet (z.B. Stunde, Minute). Für jede Zeiteinheit / Analyse-Target existiert in Cassandra eine Tabelle, für welche der Primary-Key als Verbund aus dem entsprechenden Analyse-Target (z.B. Hashtag) und der gerundeten Zeiteinheit vorliegt.
Dadurch lassen sich Updates effizient für jede Zeiteinheit / Analyse-Target durchführen.

\begin{figure}[htbp!]
	\centering
	\includegraphics[width=1.1\textwidth]{pics/analytics/example}
	\caption{Sream Analytics: Beispiel - Anzal von Hashtags pro Stunde}
\end{figure}






\include{BatchAnalysen}


\section{Analytics Provisioning Service}

Für die Bereitstellung der Analysedaten ist der Micro Service \textit{Analytics Provisioning Service} zuständig. 
Dieser liest auf Anfrage Analysedaten aus Cassandra und bereitet diese für die Darstellung im Frontend auf.
In der Batchanalyse werden die Ergebnisse geordnet in einer Tabelle pro Analyse gelegt, diese werden einfach nur für die letzten 14 Tage gelesen. Ergebnisse, die weiter in der Vergangenheit liegen, werden zur Zeit nicht bereit gestellt, dies ist theoretisch aber möglich.
Da Cassandra keine Counter als sekundäre Keys unterstützt und nicht für Sortierungen von großen Datenmengen ausgelegt ist,
die Analysedaten aus dem Stream jedoch unsortiert und nicht gefiltert vorliegen, war der naive Ansatz diese mittels einer  user-defined function in Cassandra pro Anfrage zu sortieren. Dies ist aber mit steigenden Tweetzahlen sehr aufwändig und könnte z.B. durch weitere Umsetzungen mit Spark ersetzt werden.

Die Kommunikation passiert auch hier über Kafka und festgelegte Topics.
Es lassen sich beliebig viele Instanzen des Services starten, die Kommunikation skaliert automatisch über die gewählte Kommunikationsarchitektur.

Für die Umsetzung wurde die Platform Node.js mit TypeScript verwendet. 


\section{Darstellung im Frontend}

Für die Darstellung im Frontend wurde ein eigener Bereich auf der Website eingerichtet, der wiederum in die drei Teile
\textit{Live Analytics}, \textit{Batch Analytics} und Analysen von ElasticSearchs \textit{Kibana} aufgeteilt ist.
Die Analysen durch Spark werden mittels des Frameworks \textit{Graph.js} dargestellt.



\begin{figure}[htbp!]
	\centering
	\includegraphics[width=1.1\textwidth]{pics/analytics/currentlyTrending}
	\caption{Live Analytics im Frontend}
\end{figure}
