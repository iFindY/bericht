\chapter{Webserver und Frontend}
Der Zugriff auf unsere Anwendung wurde mit dem Framework Angular realisiert. Als Schnittstelle zwischen Frontend und dem Message-Broker Kafka wurde ein Webserver geschaltet. Damit es von Außerhalb keine Möglichkeit gibt, direkt auf Kafka zuzugreifen. Ein weiterer Vorteil bei dieser Konstellation ist, dass nur die Verbindung zwischen Frontend und dem Webserver abgesichert werden. Jede weitere Kommunikation innerhalb der einzelnen Prozesse findet in einem eigenen Netzwerk statt.

\section{Frontend}
Das Frontend wurde mit dem Framework angularjs erstellt. Es gab keinen speziellen Grund, warum sich das Team für angularjs entschieden hat. Zu Beginn der Hamaube wurde auch kein Fokus auf eine Weboberfläche gesetzt. Der Fokus lag auf dem Backend und nicht dem Frontend. Da es keine Pflicht Aufgabe war und es "schnell" gehen sollte, wurde angularjs gewählt, da schon gewissen Vorkenntnisse vorhanden waren. Zudem bietet angularjs einem die Möglichkeit Module zu entwickeln, welche dann passend eingebunden werden. Der Vorteil daran ist, dass nur einmal das Layout eines Tweets definiert werden muss. Wenn der Webserver ein JSON-Dokument mit einer Liste von Tweets an das Frontend bereitstellt, kann einfach über diese Liste iteriert werden um eine Timeline zu erstellen. \\

%]Die Webanwendung sollte am Ende jedoch folgende Punkte ermöglichen.  \TODO{siehe oben?}


%\begin{itemize}
%	\item Registrieren \\
%	Ein User sollte sich in der Webanwendung Registrieren können. Dafür musste eine Username und zwei gleiche Passwörter eingegeben werden. Während dem Absenden wurde überprüft ob der Username schon belegt ist. \\
	
%	\item Einloggen \\
%	Es sollte möglich sein, nachdem sich ein User Registriert hat, sich einzuloggen.
	
%	\item Timeline anzeigen \\
%	Nach dem sich ein User eingeloggt hat, sollte der User eine Timeline sehen. Basierend auf seinen eigenen Tweets inklusiver einige aus den echten Twitter Daten. \\
	
%	\item Tweet absenden 
%	Ein User soll Tweets Absenden können. Welche im Anschluss direkt 

%\end{itemize} 
Das klassische Problem bei der Erstellung der Webanwendung war das Zugreifen auf die JSON-Dokumente. Zum Beispiel wurde das Objekt in dem JSON-Dokument in einer anderen Ebene erwartet oder beim Bezeichner wurde die Groß-/Kleinschreibung verwechselt.


\section{Webserver}
Der Webserver wurde mit dem Framework NodeJs erstellt. Dieser bietet verschiedene REST-Schnittstellen, welche mit Hilfe des Paket \textit{express} bereitgestellt wurden. Außerdem wurde eine Bibliothek für die Anbindung an Kafka implementiert. Da der Webserver nur als Vermittler fungiert, wurde eine Funktion implementiert welche zwei Parameter benötigt um das ganze so automatisiert wie möglich zu gestalten. Der erste Parameter dient dem Frage-Topic an den Kafka Server und der zweite für die Antwort in Kafka. Zusätzlich zu diesen zwei Parametern wurde eine Schnittstelle definiert, welche das Frontend mittels einer  HTTP REST-Methode ansprechen kann. Der folgende Teil beschreibt die oben beschriebene Funktion: 
Es wurde ein LoginController erstellt welcher mit den zwei Parameter \textit{USER\_ISSUES\_LOGIN} und \textit{LOGIN\_RESULT\_IS\_PROVIDED} die oben beschriebene Funktion aufruft: \\
\begin{lstlisting}[language=Java, basicstyle=\small, firstnumber=1] 
var kommunikationHandler = new KommunikationHandler
.constructor('USER_ISSUES_LOGIN', 'LOGIN_RESULT_IS_PROVIDED');
\end{lstlisting} 
Diese zwei Topics wurden in dem Kaptiel \ref{chap:Kafka} definiert. Im folgenden Code-Beispiel wird der LoginController mit einer REST-Schnittstelle \textit{/users/login} verknüpft. \\
\begin{lstlisting}[language=Java, basicstyle=\small] 
var LoginController = 	require('./endpoints/loginController');
app.use('/users/login', LoginController);
\end{lstlisting}

Durch dieses Vorgehen konnten ohne großen Aufwand weitere REST-Endpunkte mit hinterlegtem Topics für das Frontend definiert werden. \\
Probleme gab es am Anfang zwischen der Kommunikation vom Frontend und der Springboot Anwendung. Durch die Überlastung der Springboot Anwendung dauerte eine Antwort sehr lange. Damit der HTTP-Request nicht vorzeitig beendet wurde, musste ein ausreichender Timeout gesetzt werden, ansonsten lief eine Anfrage ins Leere. Um die Benutzerfreundlichkeit und Sicherheit zu erhöhen generiert der Webserver nach einer erfolgreichen Authentifizierung eine Session-Id. Somit sind alle weiteren HTTP-Requests, welche das Frontend versendet, abgesichert. \\
Nachdem die Grundfunktionalität funktionierte wurde der Webserver erweitert. \\
Das Ziel war es, mehrere Webserver parallel laufen zu haben, damit ein "Load Balancing" simuliert werden konnte. Da wir aber nur eine virtuelle Maschine zur Verfügung hatten und außerdem kein Netzwerktraffic simulieren konnten wurde das Frontend um eine weitere Funktion erweitert.
Im unteren Bereich der Webanwendung kann ein Port definiert werden. Voraussetzung, damit diese Funktion funktioniert, ist dass der Webserver drei mal auf einem verschiedenen Port gestartet wurde. Außerdem ist es nicht möglich, den Webserver während des Betriebs zu wechseln, da die drei Webserver nicht untereinander kommunizieren und somit keine Session-Ids austauschen. \\
Damit der Webserver auch während des Benutzens des Frontends gewechselt werden kann, müssten weitere Vorkehrungen getroffen werden. Um dieses Szenario zu realisieren gibt es mehrere Möglichkeiten. 
Eine Möglichkeit wäre eine Sticky-Session-Id. Dabei wird sichergestellt, dass die REST-Anfragen immer nur an den Webserver gesendet wird, von welchem die Session-Id erzeugt wurde. Der Nachteil an einer Sticky-Session-Id ist aber, dass der Vorteil eines Load Balancing verloren geht, da der Client nach einem Anmelden an den Webserver gebunden ist. Falls dieser Webserver nicht mehr verfügbar ist, muss sich der Client neu bei der Anwendung anmelden um von einem neuen verfügbaren Webserver eine neue Session-Id zu bekommen.
Damit ein Client im Betrieb unabhängig vom jeweiligen Webserver agieren kann, müssen die Webserver untereinander kommunizieren und ihre verteilten Session-Ids austauschen. Dabei kann der Austausch über eine Datenbank oder ein Dateien-System realisiert werden. Zwar bedeutet die zweite Möglichkeit einen größeren Aufwand, dafür kann die Funktionalität des  Load Balancing voll ausgeschöpft werden. Zudem kann die Performance einer Anwendung deutlich erhört werden, in dem der Load Balancer dem Client jeweils einen Webserver dynamisch zuteilt welcher im Moment genügen Kapazität zur Verfügung hat.

Wir sind davon ausgegangen, dass mehrere User gleichzeitig Anfragen im Frontend an den gleichen Webserver absenden. Da bei Kafka gesendete Anfragen nicht in der gleichen Reihenfolge abgearbeitet werden, wie sie abgesendet wurden und wir davon ausgehen, dass mehrere Anwender gleichzeitig einen Request an den selben Webserver senden, muss sichergestellt werden, dass die Antwort an den richtigen Client gesendet wird. 
Um dieses Problem zu lösen, wurde jede Anfrage von der Webanwendung an den Webserver mit einer inkrementierenden Request-Id versehen.
Diese ID wurde dem JSON-Dokument, welches an Kafka zur Bearbeitung weiter gereicht wurde, hinzugefügt. Das Antwort-Topic enthielt diese zu beginn hinzugefügte Request-ID. Somit konnte der Webserver mehrere Anfragen gleichzeitig bearbeiten und es wurde sichergestellt, dass keine Anfrage an einen falschen Client versendet wird.
